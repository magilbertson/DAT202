{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Module 3: Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topic 1: Defining/Exploring Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topic 2: Getting/Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For this topic, I'm going to show a couple of different ways to get csv files into your program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### You'll want to get comfortable with bringing data into your programs and manipulating it to the structure you need for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First I'll bring in a dataset and just output the data in my program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('zoo dataset.csv') as csvfile:\n",
    "    dataset_for_output = csv.reader(csvfile, delimiter=',')\n",
    "    for row in dataset_for_output:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### This time, I'll exclude the first row because it is headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('zoo dataset.csv') as csvfile:\n",
    "    dataset_for_output = csv.reader(csvfile, delimiter=',')\n",
    "    row_count = 0\n",
    "    for row in dataset_for_output:\n",
    "        if row_count == 0:\n",
    "            row_count +=1\n",
    "        else:   \n",
    "            print(row)\n",
    "            row_count += 1\n",
    "    print(\"total rows in file: \",row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now I'll load it into a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list_of_rows = []\n",
    "import csv\n",
    "with open('zoo dataset.csv') as csvfile:\n",
    "    dataset_for_output = csv.reader(csvfile, delimiter=',')\n",
    "    row_count = 0\n",
    "    for row in dataset_for_output:\n",
    "        if row_count == 0:\n",
    "            row_count +=1\n",
    "        else:   \n",
    "            list_of_rows.append(row)\n",
    "            row_count += 1\n",
    "    print(\"total rows in file: \",row_count)\n",
    "    print(list_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### I could also get the data imported in a different structure using DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('zoo dataset.csv') as csvfile:\n",
    "    dataset_for_output = csv.DictReader(csvfile, delimiter=',')\n",
    "    print (dataset_for_output)\n",
    "    for row in dataset_for_output:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And because we will be doing a lot of stuff with Pandas this semester, we want to be able to directly load data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open('zoo dataset.csv') as csvfile:\n",
    "    my_dataframe = pd.read_csv(\"zoo dataset.csv\") \n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topic 3: Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Web scraping is a good skill to build because it gives you a lot of opportunity to gather data from the entire web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import csv\n",
    "\n",
    "# specify the url\n",
    "urlpage =  'https://www.fasttrack.co.uk/league-tables/tech-track-100/league-table/?leagueyear=2020'\n",
    "\n",
    "# Structure the URL request to avoid 403 Forbidden Error\n",
    "page = urllib.request.Request(urlpage, headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'})\n",
    "\n",
    "# query the website and return the html to the variable 'webpage'\n",
    "webpage = urllib.request.urlopen(page).read()\n",
    "\n",
    "# parse the html using beautiful soup and store in variable 'soup'\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "print(type(soup))\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list_of_dfs = pd.read_html(webpage,index_col=False)\n",
    "print(type(list_of_dfs))\n",
    "print(len(list_of_dfs))\n",
    "print(list_of_dfs)\n",
    "my_scrape_frame = pd.DataFrame(list_of_dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_scrape_frame.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Of course, we can do better.  We're data scientists and if there are 20 years worth of data readily available, we probably want them all.  Let's loop and grab everything :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base_url =  'https://www.fasttrack.co.uk/league-tables/tech-track-100/league-table/?leagueyear='\n",
    "current_year = 2001\n",
    "my_complete_scrape_frame = pd.DataFrame(columns = ['Rank','Company','Location','Year end','Annual sales rise over 3 years','Latest sales Â£000s', 'Staff', 'Comment','Year'])\n",
    "while current_year <= 2020:\n",
    "    current_url = base_url + str(current_year)\n",
    "    print(current_url)\n",
    "    current_page = urllib.request.Request(current_url, headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'})\n",
    "    current_webpage = urllib.request.urlopen(current_page).read()\n",
    "    #print(current_webpage)\n",
    "    current_list_of_dfs = pd.read_html(current_webpage,index_col=False)\n",
    "    #print(current_list_of_dfs)\n",
    "    my_current_scrape_frame = pd.DataFrame(current_list_of_dfs[0])\n",
    "    #print(my_current_scrape_frame)\n",
    "    my_current_scrape_frame['Year']=current_year\n",
    "    print(my_current_scrape_frame)\n",
    "    my_complete_scrape_frame = my_complete_scrape_frame.append(my_current_scrape_frame,ignore_index=True)\n",
    "    print(my_complete_scrape_frame)\n",
    "    current_year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(my_complete_scrape_frame.head())\n",
    "my_complete_scrape_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topic 4: Database Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### This time I'm going to start with the easiest way to put this data into a database.  Because we ended up with a dataframe, we're going to have an easier time putting it into a database table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### I'm first creating a function that I can call to either create or connect to a sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "# This function creates a database connection and database if it doesn't already exist\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now I can call my function to get my empty database created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "db_name = \"tech_startups.db\"\n",
    "conn = create_connection(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now I'll quickly load my dataframe into my database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "my_complete_scrape_frame.to_sql(\"tech_data\",conn,if_exists='replace',index=False)\n",
    "conn.commit()\n",
    "#c.close()\n",
    "# I used if_exists=replace which drops an existing table and replaces it.\n",
    "# I could have also used fail or append to either raise an error or add to existing table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### I did the easy way of loading first.  I can also use standard SQL to do most available DB integration options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### I'm going to add another table so I can load all of the company names and locations into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "db_name = \"tech_startups.db\"\n",
    "conn = create_connection(db_name)\n",
    "\n",
    "sql_create_company_table = \"\"\"CREATE TABLE IF NOT EXISTS Company (\n",
    "                                    company_name text PRIMARY KEY,\n",
    "                                    location text\n",
    "                                );\"\"\"\n",
    "if conn is not None:\n",
    "    # create company table\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql_create_company_table)\n",
    "    conn.commit()\n",
    "    c.close()\n",
    "\n",
    "else:\n",
    "    print(\"Error! cannot create the database connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "company_list = my_complete_scrape_frame['Company'].tolist()\n",
    "company_locations = my_complete_scrape_frame['Location'].tolist()\n",
    "company_list_of_tuples = []\n",
    "for item in range(len(company_list)):\n",
    "    company_list_of_tuples.append((company_list[item],company_locations[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(company_list[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(company_list_of_tuples[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "db_name = \"tech_startups.db\"\n",
    "conn = create_connection(db_name)\n",
    "#print(company_list_of_tuples)\n",
    "sql_insert_company_table = \"INSERT or REPLACE INTO Company (company_name, location) values (?,?)\"\n",
    "#if conn is not None:\n",
    "    # insert company table\n",
    "c = conn.cursor()\n",
    "c.executemany(sql_insert_company_table, company_list_of_tuples)\n",
    "conn.commit()\n",
    "c.close()\n",
    "#else:\n",
    "    #print(\"Error! cannot create the database connection.\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
